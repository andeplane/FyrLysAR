{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymupdf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text you are looking for\n",
    "search_text = [\"Lysvidde\", \"Fyrnr.\", \"Kartnr.\"]\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "doc = pymupdf.open(pdf_path)\n",
    "\n",
    "# Iterate over all pages\n",
    "#for page_num in range(len(doc)):\n",
    "for page_num in range(140):\n",
    "    page = doc.load_page(page_num)\n",
    "    \n",
    "    # Extract text from the page\n",
    "    text = page.get_text()\n",
    "\n",
    "    # Check if the page contains the search text\n",
    "    should_parse_page = all(map(lambda needle: needle in text, search_text))\n",
    "    if should_parse_page:\n",
    "        print(f\"Text found on page {page_num + 1}\")\n",
    "        \n",
    "        # Convert the page to an image\n",
    "        pix = page.get_pixmap(dpi=200)\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        # Save the image (optional)\n",
    "        img_path = f\"pages/page_{page_num + 1}.png\"\n",
    "        img.save(img_path, quality=100)\n",
    "\n",
    "# Close the PDF document\n",
    "doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lighthouses_using_gpt(image_file_name):\n",
    "    import requests\n",
    "    import os\n",
    "    import json\n",
    "    import base64\n",
    "    file = open(image_file_name, \"rb\")\n",
    "    image_bytes = file.read()\n",
    "    base64_str = \"data:image/jpeg;base64,\" + base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    \n",
    "    openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': 'Bearer ' + os.getenv('OPENAI_API_KEY', ''),\n",
    "    }\n",
    "    \n",
    "    json_data = {\n",
    "        'model': 'gpt-4o-2024-08-06',\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': [\n",
    "                    {\n",
    "                        'type': 'text',\n",
    "                        'text': 'Generate JSON for these lighthouses. When reading sectors, use the sector color column with a single letter. Ensure that all sectors are included.',\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [\n",
    "                    {\n",
    "                        'type': 'image_url',\n",
    "                        'image_url': {\n",
    "                            'url': base64_str\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        'response_format': {\n",
    "            'type': 'json_schema',\n",
    "            'json_schema': {\n",
    "                'name': 'lighthouse_response',\n",
    "                'strict': True,\n",
    "                'schema': {\n",
    "                    '$schema': 'http://json-schema.org/draft-07/schema#',\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'items': {\n",
    "                            'type': 'array',\n",
    "                            'items': {\n",
    "                                'type': 'object',\n",
    "                                'properties': {\n",
    "                                    'latitude': {\n",
    "                                        'type': 'object',\n",
    "                                        'properties': {\n",
    "                                            'degrees': {\n",
    "                                                'type': 'integer',\n",
    "                                                'description': 'Degrees of latitude, ranging from -90 to 90.',\n",
    "                                            },\n",
    "                                            'minutes': {\n",
    "                                                'type': 'number',\n",
    "                                                'description': 'Minutes of latitude, ranging from 0 to 60.',\n",
    "                                            },\n",
    "                                        },\n",
    "                                        'required': [\n",
    "                                            'degrees',\n",
    "                                            'minutes',\n",
    "                                        ],\n",
    "                                        'additionalProperties': False,\n",
    "                                    },\n",
    "                                    'longitude': {\n",
    "                                        'type': 'object',\n",
    "                                        'properties': {\n",
    "                                            'degrees': {\n",
    "                                                'type': 'integer',\n",
    "                                                'description': 'Degrees of longitude, ranging from -180 to 180.',\n",
    "                                            },\n",
    "                                            'minutes': {\n",
    "                                                'type': 'number',\n",
    "                                                'description': 'Minutes of longitude, ranging from 0 to 60.',\n",
    "                                            },\n",
    "                                        },\n",
    "                                        'required': [\n",
    "                                            'degrees',\n",
    "                                            'minutes',\n",
    "                                        ],\n",
    "                                        'additionalProperties': False,\n",
    "                                    },\n",
    "                                    'pattern': {\n",
    "                                        'type': 'string',\n",
    "                                    },\n",
    "                                    'description': {\n",
    "                                        'type': 'string',\n",
    "                                    },\n",
    "                                    'heightOverGround': {\n",
    "                                        'type': 'number',\n",
    "                                    },\n",
    "                                    'height': {\n",
    "                                        'type': 'number',\n",
    "                                    },\n",
    "                                    'sectors': {\n",
    "                                        'type': 'array',\n",
    "                                        'items': {\n",
    "                                            'type': 'object',\n",
    "                                            'properties': {\n",
    "                                                'color': {\n",
    "                                                    'type': 'string',\n",
    "                                                },\n",
    "                                                'start': {\n",
    "                                                    'type': 'number',\n",
    "                                                },\n",
    "                                                'stop': {\n",
    "                                                    'type': 'number',\n",
    "                                                },\n",
    "                                                'description': {\n",
    "                                                    'type': 'string',\n",
    "                                                },\n",
    "                                            },\n",
    "                                            'required': [\n",
    "                                                'color',\n",
    "                                                'start',\n",
    "                                                'stop',\n",
    "                                                'description',\n",
    "                                            ],\n",
    "                                            'additionalProperties': False,\n",
    "                                        },\n",
    "                                    },\n",
    "                                    'area': {\n",
    "                                        'type': 'string',\n",
    "                                    },\n",
    "                                    'name': {\n",
    "                                        'type': 'string',\n",
    "                                    },\n",
    "                                    'location': {\n",
    "                                        'type': 'string',\n",
    "                                    },\n",
    "                                    'maxRange': {\n",
    "                                        'type': 'number',\n",
    "                                    },\n",
    "                                },\n",
    "                                'required': [\n",
    "                                    'latitude',\n",
    "                                    'longitude',\n",
    "                                    'pattern',\n",
    "                                    'description',\n",
    "                                    'heightOverGround',\n",
    "                                    'height',\n",
    "                                    'sectors',\n",
    "                                    'name',\n",
    "                                    'location',\n",
    "                                    'area',\n",
    "                                    'maxRange',\n",
    "                                ],\n",
    "                                'additionalProperties': False,\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                    'required': [\n",
    "                        'items',\n",
    "                    ],\n",
    "                    'additionalProperties': False,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        'temperature': 0.0,\n",
    "        'max_tokens': 4096,\n",
    "    }\n",
    "    \n",
    "    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=json_data)\n",
    "    data = response.json()\n",
    "    lighthouses_on_page_str = data['choices'][0]['message']['content']\n",
    "    lighthouses_on_page = json.loads(lighthouses_on_page_str)\n",
    "    return lighthouses_on_page['items']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.generative_models as generative_models\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "    \n",
    "def extract_lighthouses_using_gemini(image_file_name):\n",
    "    file = open(image_file_name, \"rb\")\n",
    "    image_bytes = file.read()\n",
    "\n",
    "    vertexai.init(project=\"cognitedata-development\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-001\",\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "\n",
    "    image = Part.from_data(mime_type=\"image/png\", data=image_bytes)\n",
    "\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": {\n",
    "            'type_': 'OBJECT',\n",
    "            'properties': {\n",
    "                'items': {\n",
    "                    'type_': 'ARRAY',\n",
    "                    'items': {\n",
    "                        'type_': 'OBJECT',\n",
    "                        'properties': {\n",
    "                            'latitude': {\n",
    "                                'type_': 'OBJECT',\n",
    "                                'properties': {\n",
    "                                    'degrees': {\n",
    "                                        'type_': 'INTEGER',\n",
    "                                        'description': 'Degrees of latitude, ranging from -90 to 90.',\n",
    "                                    },\n",
    "                                    'minutes': {\n",
    "                                        'type_': 'NUMBER',\n",
    "                                        'description': 'Minutes of latitude, ranging from 0 to 60.',\n",
    "                                    },\n",
    "                                },\n",
    "                                'required': [\n",
    "                                    'degrees',\n",
    "                                    'minutes',\n",
    "                                ]\n",
    "                            },\n",
    "                            'longitude': {\n",
    "                                'type_': 'OBJECT',\n",
    "                                'properties': {\n",
    "                                    'degrees': {\n",
    "                                        'type_': 'INTEGER',\n",
    "                                        'description': 'Degrees of longitude, ranging from -180 to 180.',\n",
    "                                    },\n",
    "                                    'minutes': {\n",
    "                                        'type_': 'NUMBER',\n",
    "                                        'description': 'Minutes of longitude, ranging from 0 to 60.',\n",
    "                                    },\n",
    "                                },\n",
    "                                'required': [\n",
    "                                    'degrees',\n",
    "                                    'minutes',\n",
    "                                ]\n",
    "                            },\n",
    "                            'pattern': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'description': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'heightOverGround': {\n",
    "                                'type_': 'NUMBER',\n",
    "                            },\n",
    "                            'height': {\n",
    "                                'type_': 'NUMBER',\n",
    "                            },\n",
    "                            'sectors': {\n",
    "                                'type_': 'ARRAY',\n",
    "                                'items': {\n",
    "                                    'type_': 'OBJECT',\n",
    "                                    'properties': {\n",
    "                                        'color': {\n",
    "                                            'type_': 'STRING',\n",
    "                                        },\n",
    "                                        'start': {\n",
    "                                            'type_': 'NUMBER',\n",
    "                                        },\n",
    "                                        'stop': {\n",
    "                                            'type_': 'NUMBER',\n",
    "                                        },\n",
    "                                        'description': {\n",
    "                                            'type_': 'STRING',\n",
    "                                        },\n",
    "                                    },\n",
    "                                    'required': [\n",
    "                                        'color',\n",
    "                                        'start',\n",
    "                                        'stop',\n",
    "                                        'description',\n",
    "                                    ]\n",
    "                                },\n",
    "                            },\n",
    "                            'area': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'name': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'location': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'maxRange': {\n",
    "                                'type_': 'NUMBER',\n",
    "                            },\n",
    "                        },\n",
    "                        'required': [\n",
    "                            'latitude',\n",
    "                            'longitude',\n",
    "                            'height',\n",
    "                            'sectors',\n",
    "                            'name',\n",
    "                            'area',\n",
    "                            'maxRange',\n",
    "                        ]\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            'required': [\n",
    "                'items',\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    safety_settings = {\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    "    \n",
    "    response = chat.send_message(\n",
    "      [image, \"Generate JSON for these lighthouses. 'Karakter' is used for flash pattern (e.g. Fl(3) W 30s). Max range is used as the max value of Lysvidde. When reading sectors, use the sector color column with a single letter. Ensure that all sectors are included.\"],\n",
    "      generation_config=generation_config,\n",
    "      safety_settings=safety_settings\n",
    "    )\n",
    "    return json.loads(response.candidates[0].content.text)['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_page_to_image(page, image_file_name):\n",
    "    pix = page.get_pixmap(dpi=200)\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    img.save(image_file_name, quality=100)\n",
    "\n",
    "def validate_text_existence(page_text, page_number, lighthouse):\n",
    "    # TODO: in case the same coordinates appear more than once, we can verify\n",
    "    # that the value appears the right amount of times (or more).\n",
    "    errors = []\n",
    "    \n",
    "    needles = {\n",
    "        \"latitude_minutes\": str(lighthouse['latitude']['minutes']),\n",
    "        \"latitude_degrees\": str(lighthouse['latitude']['degrees']),\n",
    "        \"longitude_minutes\": str(lighthouse['longitude']['minutes']),\n",
    "        \"longitude_degrees\": str(lighthouse['longitude']['degrees'])\n",
    "    }\n",
    "    \n",
    "    for sector_index, sector in enumerate(lighthouse['sectors']):\n",
    "        start_str = str(sector['start']).replace(\".\", \",\")\n",
    "        stop_str = str(sector['stop']).replace(\".\", \",\")\n",
    "        needles[f\"{sector_index}_start\"] = start_str\n",
    "        needles[f\"{sector_index}_stop\"] = stop_str\n",
    "\n",
    "    minimum_value_count = {}\n",
    "    for value in needles.values():\n",
    "        if not value in minimum_value_count:\n",
    "            minimum_value_count[value] = 0\n",
    "        minimum_value_count[value] += 1\n",
    "    \n",
    "    for key, value in needles.items():\n",
    "        value_count_on_page = page_text.count(value)\n",
    "        if value_count_on_page < minimum_value_count[value]:\n",
    "            errors.append(f\"Value {key} missing at least once for {lighthouse['name']} on page {page_number+1} (value is {value} should appear {minimum_value_count[value]} times)\")\n",
    "    return errors\n",
    "\n",
    "def validate_extracted_lighthouses(page, page_number, lighthouses):\n",
    "    page_text = page.get_text()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for lighthouse in lighthouses:\n",
    "        errors.extend(validate_text_existence(page_text, page_number, lighthouse))\n",
    "        \n",
    "    return errors\n",
    "\n",
    "def parse_lighthouses_for_page(document, page_number):\n",
    "    image_file_name = \"pages/page.png\"\n",
    "    page = document.load_page(page_number)\n",
    "    \n",
    "    convert_pdf_page_to_image(page, image_file_name)\n",
    "    # lighthouses_on_page = extract_lighthouses_using_gpt(image_file_name)\n",
    "    lighthouses_on_page = extract_lighthouses_using_gemini(image_file_name)\n",
    "    \n",
    "    # Since lower case L and upper case I looks similar,\n",
    "    # the models confuse them sometimes. We don't. Since FI \n",
    "    # is not a valid flash pattern, replace with its valid Fl value.\n",
    "    for lighthouse in lighthouses_on_page:\n",
    "        if \"pattern\" in lighthouse and \"FI\" in lighthouse[\"pattern\"]:\n",
    "            lighthouse[\"pattern\"].replace(\"FI\", \"Fl\")\n",
    "            \n",
    "    errors = validate_extracted_lighthouses(page, page_number, lighthouses_on_page)\n",
    "    return lighthouses_on_page, errors\n",
    "\n",
    "# pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "# document = pymupdf.open(pdf_path)\n",
    "# lighthouses_on_page, errors = parse_lighthouses_for_page(document, 29)\n",
    "# errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page  45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m65\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing page \u001b[39m\u001b[38;5;124m\"\u001b[39m, page_number)\n\u001b[0;32m----> 6\u001b[0m     lighthouses_on_page, errors \u001b[38;5;241m=\u001b[39m \u001b[43mparse_lighthouses_for_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m errors on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     all_errors\u001b[38;5;241m.\u001b[39mextend(errors)\n",
      "Cell \u001b[0;32mIn[51], line 52\u001b[0m, in \u001b[0;36mparse_lighthouses_for_page\u001b[0;34m(document, page_number)\u001b[0m\n\u001b[1;32m     50\u001b[0m convert_pdf_page_to_image(page, image_file_name)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# lighthouses_on_page = extract_lighthouses_using_gpt(image_file_name)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m lighthouses_on_page \u001b[38;5;241m=\u001b[39m \u001b[43mextract_lighthouses_using_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Since lower case L and upper case I looks similar,\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# the models confuse them sometimes. We don't. Since FI \u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# is not a valid flash pattern, replace with its valid Fl value.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lighthouse \u001b[38;5;129;01min\u001b[39;00m lighthouses_on_page:\n",
      "Cell \u001b[0;32mIn[50], line 145\u001b[0m, in \u001b[0;36mextract_lighthouses_using_gemini\u001b[0;34m(image_file_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8192\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     },\n\u001b[1;32m    136\u001b[0m }\n\u001b[1;32m    138\u001b[0m safety_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    139\u001b[0m     generative_models\u001b[38;5;241m.\u001b[39mHarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_HATE_SPEECH: generative_models\u001b[38;5;241m.\u001b[39mHarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_NONE,\n\u001b[1;32m    140\u001b[0m     generative_models\u001b[38;5;241m.\u001b[39mHarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_DANGEROUS_CONTENT: generative_models\u001b[38;5;241m.\u001b[39mHarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_NONE,\n\u001b[1;32m    141\u001b[0m     generative_models\u001b[38;5;241m.\u001b[39mHarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models\u001b[38;5;241m.\u001b[39mHarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_NONE,\n\u001b[1;32m    142\u001b[0m     generative_models\u001b[38;5;241m.\u001b[39mHarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_HARASSMENT: generative_models\u001b[38;5;241m.\u001b[39mHarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_NONE,\n\u001b[1;32m    143\u001b[0m }\n\u001b[0;32m--> 145\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate JSON for these lighthouses. \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKarakter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m is used for flash pattern (e.g. Fl(3) W 30s). Max range is used as the max value of Lysvidde. When reading sectors, use the sector color column with a single letter. Ensure that all sectors are included.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m  \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mtext)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1116\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, tools, stream)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message_streaming(\n\u001b[1;32m   1110\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent,\n\u001b[1;32m   1111\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   1112\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m   1113\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1236\u001b[0m, in \u001b[0;36mChatSession._send_message\u001b[0;34m(self, content, generation_config, safety_settings, tools)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     request_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_history \u001b[38;5;241m+\u001b[39m history_delta\n\u001b[0;32m-> 1236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;66;03m# By default we're not adding incomplete interactions to history.\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_validator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:700\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    693\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    694\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    695\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    699\u001b[0m )\n\u001b[0;32m--> 700\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2275\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2275\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/fyrlysar/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_errors = []\n",
    "pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "document = pymupdf.open(pdf_path)\n",
    "for page_number in range(45, 65):\n",
    "    print(\"Parsing page \", page_number)\n",
    "    lighthouses_on_page, errors = parse_lighthouses_for_page(document, page_number)\n",
    "    print(f\"Found {len(errors)} errors on page {page_number+1}\")\n",
    "    all_errors.extend(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also remember to check sector colors with their starting sector angle as it seemed like it could make mistakes sometimes. \n",
    "# This can be used to generate a list of potential problems we can/should manually fix before updating the lighthouses.json file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
