{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymupdf\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "import io\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    \"\"\"\n",
    "    Performs OCR on the given image and returns detected text elements with bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing 'description' and 'bounding_box'.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(f'API Error: {response.error.message}')\n",
    "\n",
    "    if not texts:\n",
    "        print('No text detected.')\n",
    "        return []\n",
    "\n",
    "    # Each text annotation includes description and bounding_poly\n",
    "    # The first element is the entire detected text, subsequent elements are individual words\n",
    "    text_elements = []\n",
    "    for text in texts[1:]:  # Skip the first element\n",
    "        element = {\n",
    "            'description': text.description,\n",
    "            'bounding_box': [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "        }\n",
    "        text_elements.append(element)\n",
    "\n",
    "    return text_elements\n",
    "\n",
    "def merge_text_elements(text_elements, max_x_distance=10, max_y_distance=5):\n",
    "    \"\"\"\n",
    "    Merges text elements that are horizontally close and vertically aligned based on bounding box sides.\n",
    "\n",
    "    Args:\n",
    "        text_elements (list): List of text elements with 'description' and 'bounding_box'.\n",
    "        max_x_distance (int): Maximum horizontal distance in pixels to consider for merging.\n",
    "        max_y_distance (int): Maximum vertical distance in pixels to consider for merging.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list of merged text elements.\n",
    "    \"\"\"\n",
    "    if not text_elements:\n",
    "        return []\n",
    "\n",
    "    # Sort text elements by top-left y-coordinate, then by left x-coordinate\n",
    "    sorted_elements = sorted(text_elements, key=lambda el: (el['bounding_box'][0][1], el['bounding_box'][0][0]))\n",
    "    elements_to_keep = []\n",
    "    while True:\n",
    "        merged = False\n",
    "        merged_elements = []\n",
    "        current_element = sorted_elements[0].copy()\n",
    "        \n",
    "        for next_element in sorted_elements[1:]:\n",
    "            #print(\"Considering merging \", current_element['description'], \" and \", next_element['description'])\n",
    "            #print(\"  y coordinates: \", [coord[1] for coord in current_element['bounding_box']], \" and \", [coord[1] for coord in next_element['bounding_box']])\n",
    "            # Extract bounding box coordinates\n",
    "            current_bbox = current_element['bounding_box']\n",
    "            next_bbox = next_element['bounding_box']\n",
    "\n",
    "            # Determine right side of current and left side of next\n",
    "            current_right_x = max([coord[0] for coord in current_bbox])\n",
    "            current_left_x = min([coord[0] for coord in current_bbox])\n",
    "            next_left_x = min([coord[0] for coord in next_bbox])\n",
    "            next_right_x = max([coord[0] for coord in next_bbox])\n",
    "\n",
    "            # Calculate horizontal distance between right of current and left of next\n",
    "            horizontal_distance1 = next_left_x - current_right_x\n",
    "            horizontal_distance2 = current_left_x - next_right_x\n",
    "\n",
    "            # Extract top y-coordinates for vertical alignment\n",
    "            current_top_y = current_bbox[0][1]\n",
    "            next_top_y = next_bbox[0][1]\n",
    "            vertical_distance = abs(next_top_y - current_top_y)\n",
    "            # print(\"  Vertical distance: \", vertical_distance)\n",
    "            # print(\"  Horizontal distance1: \", horizontal_distance1)\n",
    "            # print(\"  Horizontal distance2: \", horizontal_distance2)\n",
    "            # Decide whether to merge\n",
    "            if (abs(horizontal_distance1) < max_x_distance or abs(horizontal_distance2) < max_x_distance) and abs(vertical_distance) <= max_y_distance:\n",
    "                # Merge descriptions\n",
    "                # Decide which is left and which is right\n",
    "                if current_right_x < next_left_x:\n",
    "                    current_element['description'] += next_element['description']\n",
    "                else:\n",
    "                    current_element['description'] = next_element['description'] + current_element['description']\n",
    "                # Merge bounding boxes\n",
    "                # New left_x is min of current and next\n",
    "                new_left_x = min([coord[0] for coord in current_bbox] + [coord[0] for coord in next_bbox])\n",
    "                # New right_x is max of current and next\n",
    "                new_right_x = max([coord[0] for coord in current_bbox] + [coord[0] for coord in next_bbox])\n",
    "                # New top_y is min of current and next\n",
    "                new_top_y = min([coord[1] for coord in current_bbox] + [coord[1] for coord in next_bbox])\n",
    "                # New bottom_y is max of current and next\n",
    "                new_bottom_y = max([coord[1] for coord in current_bbox] + [coord[1] for coord in next_bbox])\n",
    "\n",
    "                # Define new bounding box\n",
    "                new_bounding_box = [\n",
    "                    (new_left_x, new_top_y),\n",
    "                    (new_right_x, new_top_y),\n",
    "                    (new_right_x, new_bottom_y),\n",
    "                    (new_left_x, new_bottom_y)\n",
    "                ]\n",
    "                # print(\"  Merged them!\")\n",
    "                current_element['bounding_box'] = new_bounding_box\n",
    "                merged = True\n",
    "            else:\n",
    "                # No merge; add the current element to the list\n",
    "                merged_elements.append(next_element)\n",
    "\n",
    "        # Add the last element\n",
    "        # merged_elements.append(current_element)\n",
    "        \n",
    "        # Update sorted_elements for next iteration\n",
    "        sorted_elements = merged_elements.copy()\n",
    "        # if merged:\n",
    "        #     merged_elements.insert(0, current_element)\n",
    "        elements_to_keep.append(current_element)\n",
    "        \n",
    "        # print(\"Nothing else to merge. Keeping \", current_element)\n",
    "        # elements_to_keep.append(current_element)\n",
    "        if len(sorted_elements) == 0:\n",
    "            # Finished with all elements\n",
    "            break\n",
    "        else:\n",
    "            current_element = merged_elements[0]\n",
    "                \n",
    "    return elements_to_keep\n",
    "\n",
    "def find_text(target_text, text_elements):\n",
    "    \"\"\"\n",
    "    Finds the first occurrence of the target text in the list of text elements.\n",
    "\n",
    "    Args:\n",
    "        target_text (str): The text to search for.\n",
    "        text_elements (list): List of text elements with 'description' and 'bounding_box'.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The text element containing the target text or None if not found.\n",
    "    \"\"\"\n",
    "    target_lower = target_text.strip().lower().replace(',', '').replace(' ', '').replace('.', '')\n",
    "    for element in text_elements:\n",
    "        if element['description'].strip().lower().replace(',', '').replace(' ', '').replace('.', '') == target_lower:\n",
    "            return element\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_coordinates_lysvidde(target_element):\n",
    "    \"\"\"\n",
    "    Computes new coordinates based on the position of the target text element.\n",
    "\n",
    "    Args:\n",
    "        target_element (dict): The text element containing the target text.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the new coordinates.\n",
    "    \"\"\"\n",
    "    # Assuming the bounding box is a rectangle with vertices ordered clockwise starting from top-left\n",
    "    # We'll use the top-left vertex as the reference point\n",
    "    top_left = target_element['bounding_box'][0]\n",
    "    x_target = top_left[0]\n",
    "    y_target = top_left[1]\n",
    "\n",
    "    new_coords = {\n",
    "        'x_target': x_target,\n",
    "        'y_target': y_target,\n",
    "        'x_1': x_target + 1130,\n",
    "        'y_1': y_target - 20,\n",
    "        'x_2': x_target + 1130,\n",
    "        'y_2': y_target + 3,\n",
    "        'x_3': x_target + 1130,\n",
    "        'y_3': y_target + 29\n",
    "    }\n",
    "\n",
    "    return new_coords\n",
    "\n",
    "\n",
    "def find_elements_containing_point(x, y, text_elements):\n",
    "    \"\"\"\n",
    "    Finds all text elements whose bounding boxes contain the given (x, y) point.\n",
    "\n",
    "    Args:\n",
    "        x (int): The x-coordinate of the point.\n",
    "        y (int): The y-coordinate of the point.\n",
    "        text_elements (list): List of text elements with 'description' and 'bounding_box'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of text elements containing the point.\n",
    "    \"\"\"\n",
    "    containing_elements = []\n",
    "    for element in text_elements:\n",
    "        bbox = element['bounding_box']\n",
    "        # Extract x and y coordinates separately\n",
    "        x_coords = [coord[0] for coord in bbox]\n",
    "        y_coords = [coord[1] for coord in bbox]\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        if min_x <= x <= max_x and min_y <= y <= max_y:\n",
    "            containing_elements.append(element)\n",
    "\n",
    "    return containing_elements\n",
    "\n",
    "def draw_image_with_bounding_boxes(image_path, text_elements, output_path='annotated_image.jpg'):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for element in text_elements:\n",
    "        draw.line(element['bounding_box'], fill='blue', width=2)\n",
    "    image.save(output_path)\n",
    "\n",
    "def perform_ocr(image_filename):\n",
    "    # Perform OCR on the image\n",
    "    texts_with_bounding_box = ocr_image(image_filename)\n",
    "    # texts_with_bounding_box = [{\"description\":\"Fredrikstad\",\"bounding_box\":[[207,1084],[303,1083],[303,1101],[207,1102]]},{\"description\":\"bru\",\"bounding_box\":[[309,1083],[336,1083],[336,1101],[309,1101]]},{\"description\":\",\",\"bounding_box\":[[337,1083],[342,1083],[342,1100],[337,1100]]},{\"description\":\"G\",\"bounding_box\":[[348,1083],[362,1083],[362,1100],[348,1100]]}]\n",
    "    \n",
    "    draw_image_with_bounding_boxes(image_filename, texts_with_bounding_box, f\"annotated_image.jpg\")\n",
    "    \n",
    "    # Merge text elements based on proximity\n",
    "    merged_texts = merge_text_elements(texts_with_bounding_box, max_x_distance=10, max_y_distance=5)\n",
    "    print(len(merged_texts))\n",
    "    draw_image_with_bounding_boxes(image_filename, merged_texts, f\"annotated_image_merged.jpg\")\n",
    "    return merged_texts\n",
    "\n",
    "\n",
    "def find_lysvidde(ocr_elements, lighthouse_name):\n",
    "    # Find the target text\n",
    "    target_text = find_text(lighthouse_name, ocr_elements)\n",
    "\n",
    "    if not target_text:\n",
    "        print(f\"Text '{lighthouse_name}' not found in the image.\")\n",
    "        return None\n",
    "\n",
    "    # Compute coordinates for Lysvidde\n",
    "    coords = compute_coordinates_lysvidde(target_text)\n",
    "\n",
    "    # Extract the new points\n",
    "    new_points = [\n",
    "        (coords['x_1'], coords['y_1']),\n",
    "        (coords['x_2'], coords['y_2']),\n",
    "        (coords['x_3'], coords['y_3'])\n",
    "    ]\n",
    "\n",
    "    lysvidde = None\n",
    "    # Find text elements containing these new points\n",
    "    containing_texts_dict = {}\n",
    "    for idx, (x, y) in enumerate(new_points, start=1):\n",
    "        containing_texts = find_elements_containing_point(x, y, ocr_elements)\n",
    "        containing_texts_dict[(x, y)] = containing_texts\n",
    "        if containing_texts:\n",
    "            for text in containing_texts:\n",
    "                value = float(text['description'].replace(\",\", \".\"))\n",
    "                if lysvidde is None:\n",
    "                    lysvidde = value\n",
    "                lysvidde = max(lysvidde, value)\n",
    "        \n",
    "    return lysvidde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.generative_models as generative_models\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import random\n",
    "\n",
    "locations = [\"us-central1\",\n",
    "    \"asia-east1\",\n",
    "    \"asia-east2\",\n",
    "    \"asia-northeast1\",\n",
    "    \"asia-northeast3\",\n",
    "    \"asia-south1\",\n",
    "    \"asia-southeast1\",\n",
    "    \"australia-southeast1\",\n",
    "    \"europe-central2\",\n",
    "    \"europe-north1\",\n",
    "    \"europe-southwest1\",\n",
    "    \"europe-west1\",\n",
    "    \"europe-west2\",\n",
    "    \"europe-west3\",\n",
    "    \"europe-west4\",\n",
    "    \"europe-west6\",\n",
    "    \"europe-west8\",\n",
    "    \"europe-west9\",\n",
    "    \"me-central1\",\n",
    "    \"me-central2\",\n",
    "    \"me-west1\",\n",
    "    \"northamerica-northeast1\",\n",
    "    \"southamerica-east1\",\n",
    "    \"us-east1\",\n",
    "    \"us-east4\",\n",
    "    \"us-east5\",\n",
    "    \"us-south1\",\n",
    "    \"us-west1\",\n",
    "    \"us-west4\"]\n",
    "    \n",
    "def extract_lighthouses_using_gemini(image_file_name, location):\n",
    "    file = open(image_file_name, \"rb\")\n",
    "    image_bytes = file.read()\n",
    "    \n",
    "    vertexai.init(project=\"cognitedata-development\", location=location)\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "\n",
    "    image = Part.from_data(mime_type=\"image/png\", data=image_bytes)\n",
    "\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.95,\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": {\n",
    "            'type_': 'OBJECT',\n",
    "            'properties': {\n",
    "                'items': {\n",
    "                    'type_': 'ARRAY',\n",
    "                    'items': {\n",
    "                        'type_': 'OBJECT',\n",
    "                        'properties': {\n",
    "                            'latitude': {\n",
    "                                'type_': 'OBJECT',\n",
    "                                'properties': {\n",
    "                                    'degrees': {\n",
    "                                        'type_': 'INTEGER',\n",
    "                                        'description': 'Degrees of latitude, ranging from -90 to 90.',\n",
    "                                    },\n",
    "                                    'minutes': {\n",
    "                                        'type_': 'NUMBER',\n",
    "                                        'description': 'Minutes of latitude, ranging from 0 to 60.',\n",
    "                                    },\n",
    "                                },\n",
    "                                'required': [\n",
    "                                    'degrees',\n",
    "                                    'minutes',\n",
    "                                ]\n",
    "                            },\n",
    "                            'longitude': {\n",
    "                                'type_': 'OBJECT',\n",
    "                                'properties': {\n",
    "                                    'degrees': {\n",
    "                                        'type_': 'INTEGER',\n",
    "                                        'description': 'Degrees of longitude, ranging from -180 to 180.',\n",
    "                                    },\n",
    "                                    'minutes': {\n",
    "                                        'type_': 'NUMBER',\n",
    "                                        'description': 'Minutes of longitude, ranging from 0 to 60.',\n",
    "                                    },\n",
    "                                },\n",
    "                                'required': [\n",
    "                                    'degrees',\n",
    "                                    'minutes',\n",
    "                                ]\n",
    "                            },\n",
    "                            'pattern': {\n",
    "                                'type_': 'STRING',\n",
    "                                'description': 'Flash pattern. Called Karakter in the input.',\n",
    "                            },\n",
    "                            'description': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'heightOverGround': {\n",
    "                                'type_': 'NUMBER',\n",
    "                                'description': 'Height over ground. Must be smaller than or equal height.',\n",
    "                            },\n",
    "                            'height': {\n",
    "                                'type_': 'NUMBER',\n",
    "                                'description': 'Height over sea. Must be larger than or equal to heightOverGround.',\n",
    "                            },\n",
    "                            'sectors': {\n",
    "                                'type_': 'ARRAY',\n",
    "                                'items': {\n",
    "                                    'type_': 'OBJECT',\n",
    "                                    'properties': {\n",
    "                                        'color': {\n",
    "                                            'type_': 'STRING',\n",
    "                                            'description': 'Color of sector. Typically R, G or W.',\n",
    "                                        },\n",
    "                                        'start': {\n",
    "                                            'type_': 'NUMBER',\n",
    "                                            'description': 'Start angle of sector [degrees in range 0-360].',\n",
    "                                        },\n",
    "                                        'stop': {\n",
    "                                            'type_': 'NUMBER',\n",
    "                                            'description': 'Start angle of sector [degrees in range 0-360].',\n",
    "                                        },\n",
    "                                        'description': {\n",
    "                                            'type_': 'STRING',\n",
    "                                        },\n",
    "                                    },\n",
    "                                    'required': [\n",
    "                                        'color',\n",
    "                                        'start',\n",
    "                                        'stop',\n",
    "                                        'description',\n",
    "                                    ]\n",
    "                                },\n",
    "                            },\n",
    "                            'area': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'name': {\n",
    "                                'type_': 'STRING',\n",
    "                            },\n",
    "                            'location': {\n",
    "                                'type_': 'STRING'\n",
    "                            }\n",
    "                        },\n",
    "                        'required': [\n",
    "                            'latitude',\n",
    "                            'longitude',\n",
    "                            'height',\n",
    "                            'sectors',\n",
    "                            'name',\n",
    "                            'area'\n",
    "                        ]\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            'required': [\n",
    "                'items',\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # safety_settings = {\n",
    "    #     generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    #     generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    #     generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    #     generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    # }\n",
    "    \n",
    "    response = chat.send_message(\n",
    "      [image, \"Generate JSON for these lighthouses. 'Karakter' is used for flash pattern. When reading sectors, use the sector color column with a single letter. Ensure that all sectors are included. All sector start/stop are positive numbers. If no sectors exist, or no maxRange, ignore the lighthouse.\"],\n",
    "      generation_config=generation_config,\n",
    "    )\n",
    "    \n",
    "    return json.loads(response.candidates[0].content.text)['items']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_page_to_image(page, image_file_name, mask_lysvidde):\n",
    "    pix = page.get_pixmap(dpi=200)\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    # Mask rectangle between x=1300 and x=1432\n",
    "    if mask_lysvidde:\n",
    "        for y in range(0, pix.height):\n",
    "            for x in range(1300, 1432):\n",
    "                img.putpixel((x, y), (255, 255, 255))\n",
    "    else:\n",
    "        # Mask between x in range 540, 1300 and x in range 1432, 2300\n",
    "        for y in range(0, pix.height):\n",
    "            for x in range(1000, 1300):\n",
    "                img.putpixel((x, y), (255, 255, 255))\n",
    "            for x in range(1432, 2300):\n",
    "                img.putpixel((x, y), (255, 255, 255))\n",
    "        \n",
    "    img.save(image_file_name, quality=100)\n",
    "\n",
    "def validate_text_existence(page_text, page_number, lighthouse):\n",
    "    # TODO: in case the same coordinates appear more than once, we can verify\n",
    "    # that the value appears the right amount of times (or more).\n",
    "    errors = []\n",
    "    \n",
    "    needles = {\n",
    "        \"latitude_minutes\": str(lighthouse['latitude']['minutes']),\n",
    "        \"latitude_degrees\": str(lighthouse['latitude']['degrees']),\n",
    "        \"longitude_minutes\": str(lighthouse['longitude']['minutes']),\n",
    "        \"longitude_degrees\": str(lighthouse['longitude']['degrees']),\n",
    "        \"height\": str(lighthouse['height']).replace(\".\", \",\"),\n",
    "    }\n",
    "    \n",
    "    for sector_index, sector in enumerate(lighthouse['sectors']):\n",
    "        start_str = str(sector['start']).replace(\".\", \",\")\n",
    "        stop_str = str(sector['stop']).replace(\".\", \",\")\n",
    "        needles[f\"{sector_index}_start\"] = start_str\n",
    "        needles[f\"{sector_index}_stop\"] = stop_str\n",
    "    \n",
    "    if \"pattern\" in lighthouse:\n",
    "        needles[\"pattern\"] = lighthouse[\"pattern\"]\n",
    "    \n",
    "    if \"range\" in lighthouse:\n",
    "        if lighthouse[\"range\"] == int(lighthouse[\"range\"]):\n",
    "            # maxRange will appear without decimal if it is an integer\n",
    "            needles[\"range\"] = str(int(lighthouse[\"range\"]))\n",
    "        else:\n",
    "            needles[\"range\"] = str(lighthouse[\"range\"]).replace(\".\", \",\")\n",
    "        \n",
    "    minimum_value_count = {}\n",
    "    for value in needles.values():\n",
    "        if not value in minimum_value_count:\n",
    "            minimum_value_count[value] = 0\n",
    "        minimum_value_count[value] += 1\n",
    "    \n",
    "    for key, value in needles.items():\n",
    "        value_count_on_page = page_text.count(value)\n",
    "        if value_count_on_page < minimum_value_count[value]:\n",
    "            errors.append(f\"Value {key} missing at least once for {lighthouse['name']} on page {page_number+1} (value is {value} should appear {minimum_value_count[value]} times)\")\n",
    "    return errors\n",
    "\n",
    "def validate_extracted_lighthouses(page, page_number, lighthouses):\n",
    "    page_text = page.get_text()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for lighthouse in lighthouses:\n",
    "        errors.extend(validate_text_existence(page_text, page_number, lighthouse))\n",
    "        \n",
    "    return errors\n",
    "\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "def ensure_space_before_rgw(input_string):\n",
    "    # Sometimes, there should be a space (e.g. Q W) where \n",
    "    # the language model thinks it is QW without space.\n",
    "    \n",
    "    # Regex pattern to match a letter followed by R, G, or W, but not if they follow another R, G, or W\n",
    "    pattern = r'(?<=[a-zA-Z])(?=[RGW])(?<![RGW])'\n",
    "    \n",
    "    # Replace function to add a space before R, G, or W\n",
    "    result = re.sub(pattern, ' ', input_string)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def parse_lighthouses_for_page(document, page_number):\n",
    "    image_file_name_masked_lysvidde = f\"pages/page{page_number}_masked_lysvidde.png\"\n",
    "    image_file_name_masked_rest = f\"pages/page{page_number}_masked_rest.png\"\n",
    "    page = document.load_page(page_number)\n",
    "    \n",
    "    convert_pdf_page_to_image(page, image_file_name_masked_lysvidde, mask_lysvidde=True)\n",
    "    convert_pdf_page_to_image(page, image_file_name_masked_rest, mask_lysvidde=False)\n",
    "    \n",
    "    decay_factor = 1\n",
    "    maximum_backoff = 32000\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        now = time.time()\n",
    "        if now-start > 120:\n",
    "            raise Exception(f\"Failed requests after 120 seconds to Gemini\")\n",
    "        \n",
    "        location = random.choice(locations)\n",
    "        try:\n",
    "            lighthouses_on_page = extract_lighthouses_using_gemini(image_file_name=image_file_name_masked_lysvidde, location=location)\n",
    "            \n",
    "            # Loop through lighthouses_without_range and add range from lighthouses_range\n",
    "            ocr_elements = perform_ocr(image_file_name_masked_rest)\n",
    "            for lighthouse in lighthouses_on_page:\n",
    "                # Sometimes Gemini returns a name with a newline in it\n",
    "                lighthouse[\"name\"] = lighthouse[\"name\"].split(\"\\n\")[0]\n",
    "                lysvidde = find_lysvidde(ocr_elements, lighthouse[\"name\"])\n",
    "                lighthouse['range'] = lysvidde\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling gemini on {location}: {e}\", flush=True)\n",
    "            wait_time = min(maximum_backoff, (decay_factor + random.randint(1,1000)))\n",
    "            time.sleep(wait_time / 1000) # Sleep random number of ms\n",
    "            decay_factor *= 2\n",
    "    \n",
    "    # Since lower case L and upper case I looks similar,\n",
    "    # the models confuse them sometimes. We don't. Since FI \n",
    "    # is not a valid flash pattern, replace with its valid Fl value.\n",
    "    for lighthouse in lighthouses_on_page:\n",
    "        if \"pattern\" in lighthouse:\n",
    "            if \"FI\" in lighthouse[\"pattern\"]:\n",
    "                lighthouse[\"pattern\"] = lighthouse[\"pattern\"].replace(\"FI\", \"Fl\")\n",
    "            # Sometimes lys is clipped so it looks like lvs\n",
    "            lighthouse[\"pattern\"] = lighthouse[\"pattern\"].replace(\"lvs\", \"lys\")\n",
    "            \n",
    "\n",
    "            lighthouse[\"pattern\"] = ensure_space_before_rgw(lighthouse[\"pattern\"])\n",
    "            \n",
    "    errors = validate_extracted_lighthouses(page, page_number, lighthouses_on_page)\n",
    "    return lighthouses_on_page, errors\n",
    "\n",
    "# pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "# document = pymupdf.open(pdf_path)\n",
    "# lighthouses_on_page, errors = parse_lighthouses_for_page(document, 29)\n",
    "# errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(document, page_number):\n",
    "    # Define the text you are looking for\n",
    "    search_text = [\"Lysvidde\", \"Fyrnr.\", \"Kartnr.\"]\n",
    "    \n",
    "    page = document.load_page(page_number)\n",
    "    \n",
    "    # Extract text from the page\n",
    "    text = page.get_text()\n",
    "\n",
    "    # Check if the page contains the search text\n",
    "    should_parse_page = all(map(lambda needle: needle in text, search_text))\n",
    "    if not should_parse_page:\n",
    "        return [], []\n",
    "    return parse_lighthouses_for_page(document, page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "all_errors = []\n",
    "all_lighthouses = []\n",
    "\n",
    "pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "document = pymupdf.open(pdf_path)\n",
    "\n",
    "lighthouses_per_page = [0] * len(document)\n",
    "errors_per_page = [0] * len(document)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "    futures = {executor.submit(parse_page, document, page_number): page_number for page_number in range(len(document))}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        page_number = futures[future]\n",
    "        try:\n",
    "            lighthouses_on_page, errors = future.result()\n",
    "            if len(lighthouses_on_page) > 0:\n",
    "                with open(f\"lighthouses/page_{page_number+1}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(lighthouses_on_page, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Found {len(lighthouses_on_page)} lighthouses and {len(errors)} errors on page {page_number+1}\")\n",
    "            all_errors.extend(errors)\n",
    "            all_lighthouses.extend(lighthouses_on_page)\n",
    "            lighthouses_per_page[page_number] = len(lighthouses_on_page)\n",
    "            errors_per_page[page_number] = len(errors)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing page {page_number + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "[\n",
      "  {\n",
      "    \"area\": \"Fredrikstad vestre løp\",\n",
      "    \"height\": 6.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 10.7749\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 52.3458\n",
      "    },\n",
      "    \"name\": \"Gåsungene\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Fra innover Vikerlandet til 62m SØ av Krossnefjellet lanterne.\",\n",
      "        \"start\": 184.4,\n",
      "        \"stop\": 214.8\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 107m V av nebbet S av Tankodden, klar V av grønnstakene ved Sturødgrunnen.\",\n",
      "        \"start\": 214.8,\n",
      "        \"stop\": 217.0\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 71m SV av Kråka\",\n",
      "        \"start\": 217.0,\n",
      "        \"stop\": 323.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 442m V av Måkekollflu stang\",\n",
      "        \"start\": 323.9,\n",
      "        \"stop\": 359.5\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 205m Ø av Lille Marnet, klar Ø av BRB stake på Torgautgrunnen.\",\n",
      "        \"start\": 359.5,\n",
      "        \"stop\": 18.8\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 55m Ø av Store Marnet.\",\n",
      "        \"start\": 18.8,\n",
      "        \"stop\": 34.3\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Rundtlysende.\",\n",
      "        \"start\": 0.0,\n",
      "        \"stop\": 360.0\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Elvas V side\",\n",
      "    \"pattern\": \"Oc WRG 6s\",\n",
      "    \"range\": 7.3\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Fredrikstad vestre løp\",\n",
      "    \"height\": 2.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 10.5925\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 52.3549\n",
      "    },\n",
      "    \"name\": \"Søre Kråkebåen\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Rundtlysende.\",\n",
      "        \"start\": 0.0,\n",
      "        \"stop\": 360.0\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Vesterelva\",\n",
      "    \"pattern\": \"Q (9) W 15s\",\n",
      "    \"range\": 1.6\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Fredrikstad vestre løp\",\n",
      "    \"height\": 3.6,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 11.8976\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 53.788\n",
      "    },\n",
      "    \"name\": \"Krosnesfjellet\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Rundtlysende.\",\n",
      "        \"start\": 0.0,\n",
      "        \"stop\": 360.0\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Vesterelva\",\n",
      "    \"pattern\": \"Fl R 5s\",\n",
      "    \"range\": 2.6\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Fredrikstad vestre løp\",\n",
      "    \"height\": 3.4,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 12.2889\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 54.1634\n",
      "    },\n",
      "    \"name\": \"Huthholmen\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Rundtlysende\",\n",
      "        \"start\": 0.0,\n",
      "        \"stop\": 360.0\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Østsiden på Huthholmen\",\n",
      "    \"pattern\": \"Q W\",\n",
      "    \"range\": 2.6\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Sarpsborg\",\n",
      "    \"height\": 2.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 16.2029\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 11,\n",
      "      \"minutes\": 5.465\n",
      "    },\n",
      "    \"name\": \"Amtmannsgrunnen\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Rundtlysende\",\n",
      "        \"start\": 0.0,\n",
      "        \"stop\": 360.0\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Amtmannsgrunnens V side\",\n",
      "    \"pattern\": \"Fl G 5s\",\n",
      "    \"range\": 3.0\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Sarpsborg\",\n",
      "    \"height\": 0.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 16.233\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 11,\n",
      "      \"minutes\": 5.7147\n",
      "    },\n",
      "    \"name\": \"Sarpsborg\",\n",
      "    \"sectors\": [],\n",
      "    \"pattern\": \"Fast R lys\",\n",
      "    \"range\": 3.0\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Oslofjordens østside\",\n",
      "    \"height\": 13.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 11.4589\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 45.8554\n",
      "    },\n",
      "    \"name\": \"Garnholmen\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Fra inn over land til 60m S av det vestligste skjærene ved Hankøs S-pynt.\",\n",
      "        \"start\": 242.6,\n",
      "        \"stop\": 252.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 66m N av Sildeskjær.\",\n",
      "        \"start\": 252.9,\n",
      "        \"stop\": 254.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 200m S av Sildeskjær.\",\n",
      "        \"start\": 254.9,\n",
      "        \"stop\": 270.0\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 182m N av N-ligste Navneskjærene.\",\n",
      "        \"start\": 270.0,\n",
      "        \"stop\": 278.5\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 657m V av Brotta Varde skjær.\",\n",
      "        \"start\": 278.5,\n",
      "        \"stop\": 339.6\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til klar Ø av Strutsklakkene\",\n",
      "        \"start\": 339.6,\n",
      "        \"stop\": 0.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 492m VNV av landet på Struten.\",\n",
      "        \"start\": 0.9,\n",
      "        \"stop\": 13.8\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 366m SE av Storgrunnen stang.\",\n",
      "        \"start\": 13.8,\n",
      "        \"stop\": 22.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 179m N av Nordre Missingen.\",\n",
      "        \"start\": 22.9,\n",
      "        \"stop\": 79.7\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til klar 846m SV av Rauertangen.\",\n",
      "        \"start\": 79.7,\n",
      "        \"stop\": 114.7\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 222m SV av Piggrunnen NV stang.\",\n",
      "        \"start\": 114.7,\n",
      "        \"stop\": 125.2\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til innpå Hankøkrakken\",\n",
      "        \"start\": 125.2,\n",
      "        \"stop\": 139.6\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"S innløp til Hankesundet\",\n",
      "    \"pattern\": \"Iso WRG 6s\",\n",
      "    \"range\": 6.6\n",
      "  },\n",
      "  {\n",
      "    \"area\": \"Oslofjordens østside\",\n",
      "    \"height\": 12.0,\n",
      "    \"latitude\": {\n",
      "      \"degrees\": 59,\n",
      "      \"minutes\": 10.9002\n",
      "    },\n",
      "    \"longitude\": {\n",
      "      \"degrees\": 10,\n",
      "      \"minutes\": 47.8556\n",
      "    },\n",
      "    \"name\": \"Slevik\",\n",
      "    \"sectors\": [\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Fra inn over Bløte, til 164m SW av Bløte.\",\n",
      "        \"start\": 312.7,\n",
      "        \"stop\": 322.1\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 131m W av Steinholmskjær varde.\",\n",
      "        \"start\": 322.1,\n",
      "        \"stop\": 12.3\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 225m W av Svarteskjær.\",\n",
      "        \"start\": 12.3,\n",
      "        \"stop\": 32.8\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 299m NW av Svarteskjær.\",\n",
      "        \"start\": 32.8,\n",
      "        \"stop\": 37.1\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til 34m E av j.st. W av Merrapanna.\",\n",
      "        \"start\": 37.1,\n",
      "        \"stop\": 143.4\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 50m SW av Merrapanna.\",\n",
      "        \"start\": 143.4,\n",
      "        \"stop\": 144.8\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"G\",\n",
      "        \"description\": \"Til 91m SE av Geitøya.\",\n",
      "        \"start\": 144.8,\n",
      "        \"stop\": 208.2\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"W\",\n",
      "        \"description\": \"Til 33m NW av Sauholmen.\",\n",
      "        \"start\": 208.2,\n",
      "        \"stop\": 208.9\n",
      "      },\n",
      "      {\n",
      "        \"color\": \"R\",\n",
      "        \"description\": \"Til over Langskjærene.\",\n",
      "        \"start\": 208.9,\n",
      "        \"stop\": 222.4\n",
      "      }\n",
      "    ],\n",
      "    \"location\": \"Stensholmens v side\",\n",
      "    \"pattern\": \"Oc (3) WRG 10s\",\n",
      "    \"range\": 7.2\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Fyrliste_HeleLandet.pdf\"\n",
    "document = pymupdf.open(pdf_path)\n",
    "lighthouses_on_page, errors = parse_page(document, 45)\n",
    "print(json.dumps(lighthouses_on_page, indent=2, ensure_ascii=False))\n",
    "len(lighthouses_on_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsed_lighthouses.json\", \"w\") as f:\n",
    "    json.dump(all_lighthouses, f)\n",
    "with open(\"parsed_lighthouse_errors.json\", \"w\") as f:\n",
    "    json.dump(all_errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ocr('pages/page41_masked_rest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
